{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GIS shape files into xarray masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import path\n",
    "import shapefile\n",
    "import geopandas as gpd\n",
    "import matplotlib.path as mpltPath\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_figs = './figures/'\n",
    "dir_shp = './data/LME/'\n",
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_file_base = 'LME66.shp'\n",
    "df = gpd.read_file(dir_shp+shp_file_base)\n",
    "crs_source = ('+proj=natearth +ellps=GRS80 +unit=m +lon_0=180')\n",
    "df.crs = crs_source  \n",
    "df.plot(cmap='Set2', figsize=(10, 10),vmin=0,vmax=100);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the 66_LME file to create one mask \n",
    "\n",
    "the mask contains integers signifying which LME the area pertains to \n",
    "\n",
    "individual masks can be created, but this line is commented out currently\n",
    "\n",
    "* warning: this code takes a while to go through all 66 masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats,lons=np.arange(-90,90,.1),np.arange(-180,180,.1)\n",
    "shp_file_base = 'LME66.shp'\n",
    "\n",
    "\n",
    "#create 2d grid from lats and lons\n",
    "[lon2d,lat2d]=np.meshgrid(lons,lats)\n",
    "\n",
    "#create a list of coordinates of all points within grid\n",
    "points=[]\n",
    "for latit in range(0,lats.size):\n",
    "    for lonit in range(0,lons.size):\n",
    "        point=(lon2d[latit,lonit],lat2d[latit,lonit])\n",
    "        points.append(point)\n",
    "\n",
    "#turn into np array for later\n",
    "points=np.array(points)\n",
    "\n",
    "df = gpd.read_file(dir_shp+shp_file_base)\n",
    "crs_source = ('+proj=natearth +ellps=GRS80 +unit=m +lon_0=180')\n",
    "df.crs = crs_source  \n",
    "\n",
    "indf = df.copy(deep=True)\n",
    "outdf = gpd.GeoDataFrame(columns=indf.columns)\n",
    "mask_all=np.zeros_like(lon2d)\n",
    "init_data=0\n",
    "sv_names=np.empty(67).astype('str')\n",
    "for iob in range(1,67): #1,67):\n",
    "    mask=np.zeros_like(lon2d)\n",
    "\n",
    "    subset = df.loc[df['OBJECTID']==iob]\n",
    "    name_region = subset['LME_NAME'][iob-1].replace(\" \", \"_\")\n",
    "    num_region = subset['LME_NUMBER'][iob-1].astype('int')\n",
    "    mask_region=np.ones_like(lon2d)*num_region\n",
    "\n",
    "    if 'Multi' not in str(subset.geometry.type):\n",
    "        #this code is modified from https://polarwatch.noaa.gov/tools-training/code-gallery/basic-polygon-access-visualization\n",
    "        polyListx, polyListy = subset.exterior[iob-1].xy          # perimeter of polygon\n",
    "        polyList = list(zip(list(polyListx),list(polyListy))) # formatted perimeter\n",
    "        p = mpltPath.Path(polyList)                               # path for mask\n",
    "        X, Y = np.meshgrid(lons, lats)                        # create the grid\n",
    "        points = np.array((X.flatten(), Y.flatten())).T       # break it down\n",
    "        mask = p.contains_points(points).reshape(X.shape)     # calc and grid a mask based on polygon\n",
    "        mask_all = np.ma.where(mask, mask_region, mask_all)\n",
    "        # polarwatch code end\n",
    "    else:\n",
    "        Edf2=subset.explode()\n",
    "        for index,row in Edf2.iterrows():\n",
    "            mypolygon=[]\n",
    "            for pt in list(row['geometry'].exterior.coords):\n",
    "                mypolygon.append(pt)\n",
    "            path=mpltPath.Path(mypolygon)\n",
    "            inside=path.contains_points(points)\n",
    "            inside=np.array(inside).reshape(lon2d.shape)\n",
    "            i=np.where(inside == True)\n",
    "            mask[i]=num_region\n",
    "            mask_all[i]=num_region\n",
    "    \n",
    "    ds_mask_tem=xr.Dataset(data_vars={'region_mask': (('lat','lon'),mask) },coords={'lat':lats,'lon':lons})\n",
    "    ds_mask_tem['region_mask'].attrs['LME_name'] = name_region\n",
    "    mask_name = str(num_region)+'_mask'\n",
    "#    filename_out = data_dir+mask_name+'_mask.nc'\n",
    "#    ds_mask_tem.to_netcdf(filename_out)\n",
    "    sv_names[num_region]=name_region\n",
    "ds_mask=xr.Dataset(data_vars={'region_mask': (('lat','lon'),mask_all),'LME_names':(('region'),sv_names )},coords={'lat':lats,'lon':lons,'region':np.arange(1,68,1)})\n",
    "filename_out = data_dir+'LME_all_mask.nc'\n",
    "ds_mask.to_netcdf(filename_out)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process PICES file into one mask with all values.\n",
    "- some are in lat/lon and some are in coordinate reference frame so I had to add a check for that\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process PICES file into individual masks and one mask with all values.\n",
    "#some are in lat/lon and some are in coordinate reference frame so I had to add a check for that\n",
    "\n",
    "dir_shp = './data/PICES/'\n",
    "data_dir = './data/'\n",
    "data_fig = './figures/'\n",
    "\n",
    "lats,lons=np.arange(-90,90,.1),np.arange(-180,180,.1)\n",
    "#shp_file_base = 'PICES_NPESR_Region_12.shp'\n",
    "\n",
    "\n",
    "#create 2d grid from lats and lons\n",
    "[lon2d,lat2d]=np.meshgrid(lons,lats)\n",
    "\n",
    "#create a list of coordinates of all points within grid\n",
    "points=[]\n",
    "for latit in range(0,lats.size):\n",
    "    for lonit in range(0,lons.size):\n",
    "        point=(lon2d[latit,lonit],lat2d[latit,lonit])\n",
    "        points.append(point)\n",
    "\n",
    "#turn into np array for later\n",
    "points=np.array(points)\n",
    "\n",
    "#there are some masks that wrap 180 which causes problems for the 'find inside'\n",
    "#for these there is a cheat below, instead of +lon_0=180\n",
    "#I put in +lon_0=0, create the mask then shift it to the-180,180 mask and save\n",
    "mask_all=np.zeros_like(lon2d)\n",
    "\n",
    "for root, dirs, files in os.walk(dir_shp, topdown=False):\n",
    "    if root[len(dir_shp):len(dir_shp)+1]=='.':\n",
    "        continue\n",
    "    for name in files:\n",
    "        if not name.endswith('.shp'):\n",
    "            continue\n",
    "        filename=os.path.join(root, name)\n",
    "        print(name[:-4])\n",
    "        name_region = name[:-4]\n",
    "        num_region = int(name[-6:-4])\n",
    "        df = gpd.read_file(filename)\n",
    "        if ((num_region == 13) | (num_region==14) | (num_region==23) | (num_region==24) | (num_region==15)):\n",
    "            crs_source = ('+proj=natearth +ellps=GRS80 +unit=m +lon_0=0')\n",
    "            iwrap=1\n",
    "        else:\n",
    "            crs_source = ('+proj=natearth +ellps=GRS80 +unit=m +lon_0=180')\n",
    "            iwrap=0\n",
    "        df.crs = crs_source  \n",
    "#check if in ITM or geocoordinates\n",
    "        Edf2=df.explode() #explode_polygon(df)\n",
    "        for index,row in Edf2.iterrows():\n",
    "            mypolygon=[]\n",
    "            for pt in list(row['geometry'].exterior.coords):\n",
    "                mypolygon.append(pt)\n",
    "        if (pt[0]>-180) & (pt[0]<180):\n",
    "            df2 = df.copy(deep=True)\n",
    "            print('nope: dont change coordinates')\n",
    "        else:\n",
    "            df2 = df.to_crs(epsg=4326) \n",
    "            print('yup, change coordinates')  \n",
    "        \n",
    "        init_data=0\n",
    "        mask=np.zeros_like(lon2d)\n",
    "        Edf2=df2.explode() #explode_polygon(df2)\n",
    "\n",
    "        for index,row in Edf2.iterrows():\n",
    "            #print('working on polygon', index)\n",
    "            mypolygon=[]\n",
    "            for pt in list(row['geometry'].exterior.coords):\n",
    "                mypolygon.append(pt)\n",
    "            path=mpltPath.Path(mypolygon)\n",
    "            inside=path.contains_points(points)\n",
    "            #find the results in the array that were inside the polygon ('True')\n",
    "            #and set them to missing. First, must reshape the result of the search\n",
    "            #('points') so that it matches the mask & original data\n",
    "            #reshape the result to the main grid array\n",
    "            inside=np.array(inside).reshape(lon2d.shape)\n",
    "            i=np.where(inside == True)\n",
    "            mask[i]=1\n",
    "        if (iwrap==1):\n",
    "            mask2=np.zeros(mask.shape)\n",
    "            mask2[:,1:1800]=mask[:,1801:3600]#,mask[:,1:1800]]\n",
    "            mask2[:,1800:3600]=mask[:,1:1801]\n",
    "        else:\n",
    "            mask2=mask\n",
    "        if (num_region==15):\n",
    "            mask2=mask\n",
    "            \n",
    "        mask_all= np.where(mask2==1,num_region,mask_all)\n",
    "    ds_mask_tem=xr.Dataset(data_vars={'region_mask': (('lat','lon'),mask2) },coords={'lat':lats,'lon':lons})\n",
    "    ds_masked = ds_mask_tem.where(ds_mask_tem['region_mask'] != 0)  \n",
    "    min_lat,max_lat = lat2d[np.isfinite(ds_masked.region_mask)].min(),lat2d[np.isfinite(ds_masked.region_mask)].max()\n",
    "    min_lon,max_lon = lon2d[np.isfinite(ds_masked.region_mask)].min(),lon2d[np.isfinite(ds_masked.region_mask)].max()\n",
    "    ds_mask_tem['region_mask'].attrs['PICES_name'] = name_region\n",
    "    ds_mask_tem['region_mask'].attrs['min_lon'] = min_lon\n",
    "    ds_mask_tem['region_mask'].attrs['max_lon'] = max_lon\n",
    "    ds_mask_tem['region_mask'].attrs['min_lat'] = min_lat\n",
    "    ds_mask_tem['region_mask'].attrs['max_lat'] = max_lat\n",
    "    mask_name = str(num_region)\n",
    "    filename_out = data_dir+mask_name+'_mask.nc'\n",
    "#    ds_mask_tem.to_netcdf(filename_out)\n",
    "ds_mask_tem=xr.Dataset(data_vars={'region_mask': (('lat','lon'),mask_all) },coords={'lat':lats,'lon':lons})\n",
    "ds_masked = ds_mask_tem.where(ds_mask_tem['region_mask'] != 0)  \n",
    "min_lat,max_lat = lat2d[np.isfinite(ds_masked.region_mask)].min(),lat2d[np.isfinite(ds_masked.region_mask)].max()\n",
    "min_lon,max_lon = lon2d[np.isfinite(ds_masked.region_mask)].min(),lon2d[np.isfinite(ds_masked.region_mask)].max()\n",
    "ds_mask_tem['region_mask'].attrs['PICES_name'] = 'all'\n",
    "ds_mask_tem['region_mask'].attrs['min_lon'] = min_lon\n",
    "ds_mask_tem['region_mask'].attrs['max_lon'] = max_lon\n",
    "ds_mask_tem['region_mask'].attrs['min_lat'] = min_lat\n",
    "ds_mask_tem['region_mask'].attrs['max_lat'] = max_lat\n",
    "mask_name = 'PICES_all'\n",
    "filename_out = data_dir+mask_name+'_mask.nc'\n",
    "ds_mask_tem.to_netcdf(filename_out)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
