{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and create timeseries using PICES LME\n",
    "\n",
    "Look at SST, ocean currents, chl-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('./subroutines/')\n",
    "import pices\n",
    "\n",
    "adir_data = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data (mean, climatology, anomaly) data for PICES region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mn,clim,anom = pices.get_pices_data('current',13,'1992-01-01','2019-08-01')\n",
    "#mn,clim,anom = pices.get_pices_data('chl',13,'1992-01-01','2019-08-01')\n",
    "#mn,clim,anom = pices.get_pices_data('sst',13,'1992-01-01','2019-08-01')\n",
    "mn,clim,anom = pices.get_pices_data('wind',13,'1992-01-01','2019-08-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in anom:\n",
    "    anom[a].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop here\n",
    "\n",
    "The code below here is slow and takes a while to run because it is accessing data online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in PICES mask\n",
    "\n",
    "- Each dataset finds a unique and different way to define lat / lon or order them.\n",
    "- There is a need for standardization in this area\n",
    "- The basic PICES mask is -180 to 180 lon and -90 to 90 lat\n",
    "- Below different maps are created for 0 to 360 lon\n",
    "- Then each of the two different lon maps are also copied to reverse lat, 90 to -90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pices360 = pices.get_pices_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pices360.sel(lon=slice(115,250),lat=slice(20,70)).region_mask.plot(vmin=11,vmax=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pices360.region_mask.plot.hist(bins=np.arange(10.5,27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in SST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pices.get_filename('sst')\n",
    "\n",
    "ds = xr.open_dataset(file)\n",
    "print('lat range',ds.lat[0].data,ds.lat[-1].data)\n",
    "print('lon range',ds.lon[0].data,ds.lon[-1].data)\n",
    "\n",
    "#interpolate mask\n",
    "mask_interp = ds_pices360_revlat.interp_like(ds,method='nearest')\n",
    "\n",
    "\n",
    "#create sst mean for pices region\n",
    "for iregion in range(11,25):\n",
    "    cond = (mask_interp.region_mask==iregion)\n",
    "    tem = weighted_mean_of_data(ds.sst,cond)\n",
    "    tem=tem.assign_coords(region=iregion)\n",
    "    if iregion==11:\n",
    "        sst_mean=tem\n",
    "    else:\n",
    "        sst_mean = xr.concat([sst_mean, tem], dim='region')\n",
    "\n",
    "#make climatology and anomalies using .groupby method\n",
    "sst_climatology = sst_mean.groupby('time.month').mean('time')\n",
    "sst_anomalies = sst_mean.groupby('time.month') - sst_climatology\n",
    "\n",
    "sst_mean.to_netcdf(adir_data+'sst_mean.nc')\n",
    "sst_climatology.to_netcdf(adir_data+'sst_climatology.nc')\n",
    "sst_anomalies.to_netcdf(adir_data+'sst_anomalies.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdlasFnWind10'\n",
    "ds = xr.open_dataset(aggr_url).rename({'latitude':'lat','longitude':'lon'}).drop({'taux_mean','tauy_mean','curl'})\n",
    "print('lat range',ds.lat[0].data,ds.lat[-1].data)\n",
    "print('lon range',ds.lon[0].data,ds.lon[-1].data)\n",
    "\n",
    "#interpolate mask\n",
    "mask_interp = ds_pices360.interp_like(ds,method='nearest')\n",
    "\n",
    "for iregion in range(11,25):\n",
    "    cond = (mask_interp.region_mask==iregion)\n",
    "    tem = weighted_mean_of_data(ds,cond)\n",
    "    tem=tem.assign_coords(region=iregion)\n",
    "    if iregion==11:\n",
    "        wnd_mean=tem\n",
    "    else:\n",
    "        wnd_mean = xr.concat([wnd_mean, tem], dim='region')\n",
    "\n",
    "#make climatology and anomalies using .groupby method\n",
    "wnd_climatology = wnd_mean.groupby('time.month').mean('time')\n",
    "wnd_anomalies = wnd_mean.groupby('time.month') - wnd_climatology\n",
    "\n",
    "wnd_mean.to_netcdf(adir_data+'wnd_mean.nc')\n",
    "wnd_climatology.to_netcdf(adir_data+'wnd_climatology.nc')\n",
    "wnd_anomalies.to_netcdf(adir_data+'wnd_anomalies.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Ocean current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplOscar'\n",
    "ds = xr.open_dataset(aggr_url).isel(depth=0).rename({'latitude':'lat','longitude':'lon'}).drop({'um','vm'})\n",
    "print('lat range',ds.lat[0].data,ds.lat[-1].data)\n",
    "print('lon range',ds.lon[0].data,ds.lon[-1].data)\n",
    "\n",
    "#subset\n",
    "ds = ds.sel(lon=slice(115,250),lat=slice(70,20))\n",
    "\n",
    "#interpolate mask\n",
    "mask_interp = ds_pices360_revlat.interp_like(ds,method='nearest')\n",
    "\n",
    "for iregion in range(11,25):\n",
    "    cond = (mask_interp.region_mask==iregion)\n",
    "    tem = weighted_mean_of_data(ds,cond)\n",
    "    tem=tem.assign_coords(region=iregion)\n",
    "    if iregion==11:\n",
    "        cur_mean=tem\n",
    "    else:\n",
    "        cur_mean = xr.concat([cur_mean, tem], dim='region')\n",
    "\n",
    "#make climatology and anomalies using .groupby method\n",
    "cur_climatology = cur_mean.groupby('time.month').mean('time')\n",
    "cur_anomalies = cur_mean.groupby('time.month') - cur_climatology\n",
    "\n",
    "cur_mean.to_netcdf(adir_data+'cur_mean.nc')\n",
    "cur_climatology.to_netcdf(adir_data+'cur_climatology.nc')\n",
    "cur_anomalies.to_netcdf(adir_data+'cur_anomalies.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in chl-a data\n",
    "\n",
    "- The chl-a data is on a 4km grid, too high resolution to deal unless running on the cloud.\n",
    "- For now, it is subsetted and interpolated onto a 1 deg grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# don't run this\n",
    "- create local files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create local files for currents, winds, chl-a from monthly files on hard drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currents\n",
    "file = './data/sst.mnmean.nc'\n",
    "ds_sst=xr.open_dataset(file)\n",
    "ds_sst.close()\n",
    "\n",
    "#aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/jplOscar'\n",
    "aggr_url='F:/data/sat_data/oscar/L4/oscar_1_deg/*.gz'\n",
    "ds = xr.open_mfdataset(aggr_url).isel(depth=0).rename({'latitude':'lat','longitude':'lon'}).drop({'uf','vf'})\n",
    "date1 = pd.Series(pd.period_range('1992-10-01', periods=27*12, freq='M'))\n",
    "init=0\n",
    "for d in date1:\n",
    "    dstr=str(d.year)+'-'+str(d.month).zfill(2)\n",
    "    dstr2=str(d.year)+'-'+str(d.month).zfill(2)+'-01'\n",
    "    ds2=ds.sel(time=slice(dstr,dstr)).sel(lon=slice(20.0,379.9)).drop({'date'}).load()\n",
    "    ds2 = ds2.assign_coords(lon=np.mod(ds2['lon'], 360)).sortby('lon').sortby('lat',ascending=True)\n",
    "    ds3 = ds2.interp(lat=ds_sst.lat,lon=ds_sst.lon,method='linear').mean('time',keep_attrs=True)\n",
    "    ds3=ds3.assign_coords(time=np.datetime64(dstr2))\n",
    "    if init==0:\n",
    "        ts=ds3\n",
    "        init=init+1\n",
    "    else:\n",
    "        ts=xr.concat((ts,ds3),dim='time')\n",
    "        #break\n",
    "ts.to_netcdf('.\\data\\cur.mnmean.nc',encoding={'u': {'dtype': 'int8', 'scale_factor': 0.015, '_FillValue': -128},'v': {'dtype': 'int8', 'scale_factor': 0.015, '_FillValue': -128},'mask': {'dtype': 'int8', 'scale_factor': 1, '_FillValue': -1}})   \n",
    "#ts.to_netcdf('.\\data\\cur.mnmean.nc',encoding={'u': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},'v': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999}},'mask': {'dtype': 'int8', 'scale_factor': 1, '_FillValue': -1})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chl-a\n",
    "aggr_url='f:/data/ocean_color/month/all/*.nc'\n",
    "ds = xr.open_mfdataset(aggr_url,concat_dim='time')\n",
    "ds = ds.sortby(ds.lat)\n",
    "ds.coords['lon'] = np.mod(ds['lon'], 360)\n",
    "ds = ds.sortby(ds.lon)\n",
    "ds = ds.drop({'CHL1_flags','CHL1_error'})\n",
    "date1 = pd.Series(pd.period_range('1997-09-01', periods=265, freq='M'))\n",
    "for d in date1:\n",
    "    dstr2=str(d.year)+'-'+str(d.month).zfill(2)+'-01'\n",
    "    tstr.append(np.datetime64(dstr2))\n",
    "ds=ds.assign_coords(time=tstr)\n",
    "file = pices.get_filename('chl')\n",
    "ds.to_netcdf(file,encoding={'CHL1_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999}})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wind\n",
    "file = pices.get_filename('wind')\n",
    "aggr_url = 'https://coastwatch.pfeg.noaa.gov/erddap/griddap/erdlasFnWind10'\n",
    "ds = xr.open_dataset(aggr_url).rename({'latitude':'lat','longitude':'lon'}).drop({'taux_mean','tauy_mean','curl','uv_mag_mean'})\n",
    "ds\n",
    "ds.to_netcdf(file,encoding={'u_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},'v_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999}})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
